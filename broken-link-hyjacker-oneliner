while read url; do timeout 15 blc -rfoi --exclude linkedin.com --exclude youtube.com --filter-level 0 $url >.a.txt; cat .a.txt | grep "ERRNO_ENOTFOUND" | awk -F[/:] '{print $4}' | awk -F "." '{print $(NF-1)"."$NF}' | { read d; echo $d | xargs -I % sh -c "whois %" | xargs -I % bash -c "if [[ '%' == *' is free' ]]; then echo 'FOUND - $d, crawling $url'; fi"; } ; done<allUrls.txt; rm .a.txt
